{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e173258-e874-44cf-9c43-204f59a42757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import Trainer\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7f44f6-e30e-4f7f-941a-f36b3faca684",
   "metadata": {},
   "source": [
    "# Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d63737f-b2e4-4a40-bbc3-f86350b7bf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /data/vm_train_data/top_vendor_hard_cases/multilabel_vm_classifier_azure_tagged.json...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26f84796e974e48b142841a468218b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4915 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current size: 4915;  Acc conflict: 0\n",
      "\n",
      "Loading /data/vm_train_data/andrew_dataset_partition/main_train_simply_converted.json...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534736df734c4d10a1df717f178b655a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1153454 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current size: 1123662;  Acc conflict: 34707\n",
      "\n",
      "Loading /data/vm_train_data/andrew_dataset_partition/main_test_simply_converted.json...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ec4661b8f64792859156a158baca99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228960 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current size: 1340650;  Acc conflict: 46679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iterate the json file in order (priority: High -> Low)\n",
    "added_uuids= set()\n",
    "conflict_count = 0\n",
    "tagged_data = []\n",
    "\n",
    "\n",
    "# The order is super important\n",
    "all_datasource = [\n",
    "    '/data/vm_train_data/top_vendor_hard_cases/',\n",
    "    '/data/vm_train_data/negative/',\n",
    "    # ## and more ...\n",
    "    '/data/vm_train_data/andrew_dataset_partition/main_train_simply_converted.json',\n",
    "    '/data/vm_train_data/andrew_dataset_partition/main_test_simply_converted.json',\n",
    "    ## ...\n",
    "    \n",
    "]\n",
    "\n",
    "for ds in all_datasource:\n",
    "    for json_file in get_json_paths(ds):\n",
    "        print(f'Loading {json_file}...')\n",
    "        tmp_json = json.load(open(json_file))\n",
    "        for d in tqdm(tmp_json):\n",
    "            uuid = d.get('uuid', '')\n",
    "            if uuid and uuid in added_uuids:\n",
    "                conflict_count += 1\n",
    "                continue\n",
    "            else:\n",
    "                if not d['items_label']:\n",
    "                    d['items_label'] = [['', '']]\n",
    "                tagged_data.append(d)\n",
    "                added_uuids.add(uuid)\n",
    "        print('Current size: {};  Acc conflict: {}'.format(len(tagged_data), conflict_count))\n",
    "        print()\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9e42f2-0028-4e95-8617-572d7876af77",
   "metadata": {},
   "source": [
    "## Build the map:   id <=> name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e4b07a-715b-4861-8149-dfedf3b91f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 1339479),\n",
       " ('Bytes Software Services', 206),\n",
       " ('KPCS Consulting', 149),\n",
       " ('Onyx Technology', 136),\n",
       " ('CDW Corporation', 134),\n",
       " ('Microsoft Azure', 83),\n",
       " ('ozBeanz', 82),\n",
       " ('Sikich', 71),\n",
       " ('Henson Group', 54),\n",
       " ('Carahsoft Technology Corp', 36)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "platform_counter = Counter([d['reseller_label'] for d in tagged_data])\n",
    "platform_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c321903-08c7-4676-9409-530f5a7c663a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_list = []\n",
    "for d in tagged_data:\n",
    "    for item in d['items_label']:\n",
    "        tmp_list.append(tuple(item))\n",
    "product_counter = Counter(tmp_list)\n",
    "del tmp_list\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7230a75-5d6d-4d30-97ce-61a8bec57341",
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_count_thres = 1\n",
    "platform_name_2_id = {}\n",
    "product_count_thres = 10\n",
    "product_name_2_id = {}\n",
    "\n",
    "platform_name_2_id[''] = 0\n",
    "\n",
    "# build maps\n",
    "i = 1\n",
    "for k, v in platform_counter.most_common():\n",
    "    if v >= platform_count_thres and k != '':\n",
    "        platform_name_2_id[k] = i\n",
    "        i += 1\n",
    "platform_id_2_name = {v:k for k, v in platform_name_2_id.items()}\n",
    "\n",
    "\n",
    "product_name_2_id[('', '')] = i\n",
    "i += 1\n",
    "for k, v in product_counter.most_common():\n",
    "    if v >= product_count_thres and k != ('', ''):\n",
    "        product_name_2_id[k] = i\n",
    "        i += 1\n",
    "product_id_2_name = {v:k for k, v in product_name_2_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0a4c237-c567-47ce-8f77-b8894f00bd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "4550\n"
     ]
    }
   ],
   "source": [
    "platform_class_num = len(platform_id_2_name)\n",
    "product_class_num = len(product_id_2_name)\n",
    "print(platform_class_num)\n",
    "print(product_class_num)\n",
    "\n",
    "id2label = {}\n",
    "for k, v in platform_id_2_name.items():\n",
    "    id2label[k] = v\n",
    "for k, v in product_id_2_name.items():\n",
    "    id2label[k] = v\n",
    "\n",
    "label2id = {v:k for k,v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71a4379a-6a73-43c6-9424-7cec99b40682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54bbc28898dc4d48a7baac496d337964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1340650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def gen_text(transaction_dict):\n",
    "    return 'payee: {} ### note: {} \\t {}'.format(transaction_dict['vendor_name'], transaction_dict['memo'], transaction_dict['memo_2'])\n",
    "\n",
    "texts = []\n",
    "platform_label_list = []\n",
    "product_label_list = []\n",
    "merge_label_list = []\n",
    "\n",
    "# platform_sparse_label_list = []\n",
    "# product_sparse_label_list = []\n",
    "sparse_label_list = []\n",
    "\n",
    "for d in tqdm(tagged_data):\n",
    "    text = gen_text(d)\n",
    "    platform_label = []\n",
    "    texts.append(text)\n",
    "\n",
    "    platform_sparse_label = []\n",
    "    i = platform_name_2_id.get(d['reseller_label'], None)\n",
    "    if i != None:\n",
    "        platform_sparse_label.append(i)\n",
    "    if len(platform_sparse_label) == 0:\n",
    "        platform_sparse_label = [platform_name_2_id['']]\n",
    "\n",
    "    product_sparse_label = []\n",
    "    for item in d.get('items_label', []):\n",
    "        i = product_name_2_id.get(tuple(item), None)\n",
    "        if i != None:\n",
    "            product_sparse_label.append(i)\n",
    "    if len(product_sparse_label) == 0:\n",
    "        product_sparse_label = [product_name_2_id[('', '')]]\n",
    "\n",
    "    sparse_label_list.append([platform_sparse_label, product_sparse_label])\n",
    "\n",
    "# del tagged_data\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed3e2ed3-c531-4896-87a4-3aff1a088781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0], [36]],\n",
       " [[0], [36]],\n",
       " [[0], [36]],\n",
       " [[0], [36]],\n",
       " [[0], [36]],\n",
       " [[0], [36]],\n",
       " [[0], [36]],\n",
       " [[0], [36]],\n",
       " [[0], [36]],\n",
       " [[0], [36]]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_label_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc304c56-9a98-4703-8d13-34fad5c240e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1332915\n",
      "7735\n"
     ]
    }
   ],
   "source": [
    "pos_texts = []\n",
    "neg_texts = []\n",
    "\n",
    "pos_labels = []\n",
    "neg_labels = []\n",
    "\n",
    "for (text, sparse_label) in zip(texts, sparse_label_list):\n",
    "    platform_sparse_label, product_sparse_label = sparse_label\n",
    "    if platform_sparse_label[0] == platform_name_2_id[''] and product_sparse_label[0] == product_name_2_id[('','')]:\n",
    "        neg_texts.append(text)\n",
    "        neg_labels.append(sparse_label)\n",
    "    else:\n",
    "        pos_texts.append(text)\n",
    "        pos_labels.append(sparse_label)\n",
    "\n",
    "print(len(pos_texts))\n",
    "print(len(neg_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9a46062-afa0-401e-843f-7047077fe602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1340650\n"
     ]
    }
   ],
   "source": [
    "# balanced_texts = pos_texts + neg_texts[:len(pos_texts)]\n",
    "# balanced_labels = pos_labels + neg_labels[:len(pos_labels)]\n",
    "\n",
    "balanced_texts = pos_texts + neg_texts[:len(pos_texts)]\n",
    "balanced_labels = pos_labels + neg_labels[:len(pos_labels)]\n",
    "\n",
    "print(len(balanced_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abd408c0-4d23-4601-a536-12be6edd05ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 1206585\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 134065\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_dataset = Dataset.from_dict({\n",
    "    'text': balanced_texts,\n",
    "    'labels': balanced_labels,\n",
    "})\n",
    "orig_dataset = orig_dataset.train_test_split(test_size=0.1)\n",
    "orig_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3a2dba2-006f-489a-8a34-9381149b9130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_name = 'distilbert/distilroberta-base'\n",
    "max_length = 128\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    # take a batch of texts\n",
    "    text = examples[\"text\"]\n",
    "    # encode them\n",
    "    encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=max_length)\n",
    "    # # copy labels\n",
    "    # encoding[\"labels\"] = examples[\"labels\"]\n",
    "\n",
    "    concat_labels_list = []\n",
    "    for platform_labels, product_labels in examples[\"labels\"]:\n",
    "        concat_labels = []\n",
    "        concat_labels.extend(platform_labels)\n",
    "        concat_labels.extend(product_labels)\n",
    "        padded_x = concat_labels + [-1] * (5 - len(concat_labels))\n",
    "        concat_labels_list.append(padded_x)\n",
    "\n",
    "    encoding[\"labels\"] = concat_labels_list\n",
    "    return encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3b4150b-fa8d-41c0-95d1-9d5156cb7737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ef82c3553e49fc817e5d9dce8ed8bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1206585 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa86359eb244063bc1326d493e6d101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/134065 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1206585\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 134065\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset = orig_dataset.map(preprocess_data, batched=True, remove_columns=orig_dataset['train'].column_names)\n",
    "# encoded_dataset = orig_dataset.map(preprocess_data, batched=True)\n",
    "encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7332845-b92c-47e5-86b4-4ccb9f8c51ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 291, -1, -1, -1],\n",
       " [0, 138, -1, -1, -1],\n",
       " [0, 50, -1, -1, -1],\n",
       " [0, 141, -1, -1, -1],\n",
       " [0, 74, -1, -1, -1],\n",
       " [0, 4241, -1, -1, -1],\n",
       " [0, 3539, -1, -1, -1],\n",
       " [0, 235, -1, -1, -1],\n",
       " [0, 911, -1, -1, -1],\n",
       " [0, 60, -1, -1, -1]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['test']['labels'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d8c3f38-5842-4dc0-95d2-2de44033bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba16b4a8-5380-49dc-ace6-e24b69661aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, RobertaForSequenceClassification\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import math\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "from packaging import version\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "\n",
    "# pos_weights = torch.ones(platform_class_num + product_class_num) * 2.0\n",
    "# pos_weights[0] = 1.0\n",
    "# pos_weights[platform_class_num] = 1.0\n",
    "# pos_weights = pos_weights.to('cuda:0')\n",
    "# print(pos_weights)\n",
    "\n",
    "\n",
    "class CustomModelForSequenceClassification(RobertaForSequenceClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        token_type_ids: Optional[torch.LongTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        sequence_output = outputs[0]\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # move labels to correct device to enable model parallelism\n",
    "            labels = labels.to(logits.device)\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                # loss_fct = BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                multi_hot_labels = torch.zeros_like(logits)\n",
    "                for i in range(len(labels)):\n",
    "                    for v in labels[i]:\n",
    "                        if v != -1:\n",
    "                            multi_hot_labels[i][v] = 1.0\n",
    "                        else:\n",
    "                            break\n",
    "                # print(logits)\n",
    "                # print(logits.shape)\n",
    "                # print(labels)\n",
    "                # print(labels.shape)\n",
    "                # print(multi_hot_labels)\n",
    "                multi_hot_labels = multi_hot_labels.to(logits.device)\n",
    "                # print('logits', logits)\n",
    "                # print('multi_hot_labels', multi_hot_labels)\n",
    "                loss = loss_fct(logits, multi_hot_labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19396956-554d-4d68-86e7-3193cf09e6c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CustomModelForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomModelForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=4585, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CustomModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    problem_type=\"multi_label_classification\", \n",
    "    num_labels=len(id2label),\n",
    ")\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f8029b0-aeff-40c6-9098-b580b0ea96a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"/data/trained_models/new_vm_model_1217\",\n",
    "    eval_strategy = \"steps\",\n",
    "    save_strategy = \"steps\",\n",
    "    logging_steps = 20000,\n",
    "    save_steps = 20000,\n",
    "    learning_rate=2e-4,\n",
    "    # lr_scheduler_type=\"cosine\",  # Learning rate scheduler\n",
    "    # warmup_steps=10000,  # Number of warmup steps\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=128,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    "    # load_best_model_at_end=False,\n",
    "    # metric_for_best_model=\"eval_product_f1\",    \n",
    "    # push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4170d221-7788-4467-afda-ee2d334a8a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "    \n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    y_pred = np.zeros_like(predictions)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "\n",
    "    y_true = np.zeros_like(y_pred)\n",
    "    for i in range(len(labels)):\n",
    "        for v in labels[i]:\n",
    "            if v != -1:\n",
    "                y_true[i, v] = 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    # precision_micro = precision_score(y_true, y_pred, average=\"micro\")\n",
    "    # recall_micro = recall_score(y_true, y_pred, average=\"micro\")\n",
    "    # f1_micro = f1_score(y_true, y_pred, average=\"micro\")\n",
    "    # accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # metrics = {\n",
    "    #     'precistion': precision_micro,\n",
    "    #     'recall': recall_micro,\n",
    "    #     'f1': f1_micro,\n",
    "    #     'accuracy': accuracy,\n",
    "    # }\n",
    "\n",
    "    y_pred_platform = y_pred[:, :platform_class_num]\n",
    "    y_true_platform = y_true[:, :platform_class_num]\n",
    "    y_pred_product = y_pred[:, platform_class_num:]\n",
    "    y_true_product = y_true[:, platform_class_num:]\n",
    "\n",
    "    platform_precision_micro = precision_score(y_true_platform, y_pred_platform, average=\"micro\")\n",
    "    platform_recall_micro = recall_score(y_true_platform, y_pred_platform, average=\"micro\")\n",
    "    platform_f1_micro = f1_score(y_true_platform, y_pred_platform, average=\"micro\")\n",
    "    platform_acc_micrio = accuracy_score(y_true_platform, y_pred_platform)\n",
    "    \n",
    "    product_precision_micro = precision_score(y_true_product, y_pred_product, average=\"micro\")\n",
    "    product_recall_micro = recall_score(y_true_product, y_pred_product, average=\"micro\")\n",
    "    product_f1_micro = f1_score(y_true_product, y_pred_product, average=\"micro\")\n",
    "    product_acc_micro = accuracy_score(y_true_product, y_pred_product)\n",
    "\n",
    "    metrics = {\n",
    "        'platform_precistion': platform_precision_micro,\n",
    "        'platform_recall': platform_recall_micro,\n",
    "        'platform_f1': platform_f1_micro,\n",
    "        'platform_accuracy': platform_acc_micrio,\n",
    "        \n",
    "        'product_precistion': product_precision_micro,\n",
    "        'product_recall': product_recall_micro,\n",
    "        'product_f1': product_f1_micro,\n",
    "        'product_accuracy': product_acc_micro,\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82f5a0be-c130-4d90-aa90-3f997e1f0475",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152c1297-5767-4f93-bd53-4ae78d972d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6363' max='301648' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  6363/301648 10:56 < 8:27:34, 9.70 it/s, Epoch 0.17/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fda2afb2-ed25-47ba-b6b8-bb5372cd819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/trained_models/new_vm_model_1217/id2label.json', 'w') as f:\n",
    " json.dump(id2label, f)\n",
    "\n",
    "with open('/data/trained_models/new_vm_model_1217/trainer_log_history.json', 'w') as f:\n",
    " json.dump(trainer.state.log_history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d2c27000-eda4-48a1-9bfd-65a685aa957c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.0018,\n",
       "  'grad_norm': 0.0011410280130803585,\n",
       "  'learning_rate': 0.00018673951095316395,\n",
       "  'epoch': 0.5304195618734419,\n",
       "  'step': 20000},\n",
       " {'eval_loss': 0.0006158497417345643,\n",
       "  'eval_platform_precistion': 0.9992317159586768,\n",
       "  'eval_platform_recall': 0.9992317159586768,\n",
       "  'eval_platform_f1': 0.9992317159586768,\n",
       "  'eval_platform_accuracy': 0.9992317159586768,\n",
       "  'eval_product_precistion': 0.8974172629695886,\n",
       "  'eval_product_recall': 0.47894383530991275,\n",
       "  'eval_product_f1': 0.6245635194677612,\n",
       "  'eval_product_accuracy': 0.4785514489240294,\n",
       "  'eval_runtime': 467.8766,\n",
       "  'eval_samples_per_second': 286.539,\n",
       "  'eval_steps_per_second': 2.24,\n",
       "  'epoch': 0.5304195618734419,\n",
       "  'step': 20000},\n",
       " {'loss': 0.0004,\n",
       "  'grad_norm': 0.0010074255988001823,\n",
       "  'learning_rate': 0.00017347902190632792,\n",
       "  'epoch': 1.0608391237468837,\n",
       "  'step': 40000},\n",
       " {'eval_loss': 0.00028129343991167843,\n",
       "  'eval_platform_precistion': 0.9997238496846662,\n",
       "  'eval_platform_recall': 0.9991272890016037,\n",
       "  'eval_platform_f1': 0.9994254803208357,\n",
       "  'eval_platform_accuracy': 0.9991272890016037,\n",
       "  'eval_product_precistion': 0.9550562833620666,\n",
       "  'eval_product_recall': 0.772685910345342,\n",
       "  'eval_product_f1': 0.8542461212423569,\n",
       "  'eval_product_accuracy': 0.7707156976093686,\n",
       "  'eval_runtime': 457.4811,\n",
       "  'eval_samples_per_second': 293.05,\n",
       "  'eval_steps_per_second': 2.291,\n",
       "  'epoch': 1.0608391237468837,\n",
       "  'step': 40000},\n",
       " {'loss': 0.0003,\n",
       "  'grad_norm': 0.0017288732342422009,\n",
       "  'learning_rate': 0.00016021853285949186,\n",
       "  'epoch': 1.5912586856203257,\n",
       "  'step': 60000},\n",
       " {'eval_loss': 0.00019066261302214116,\n",
       "  'eval_platform_precistion': 0.9998060005521523,\n",
       "  'eval_platform_recall': 0.9994778652146347,\n",
       "  'eval_platform_f1': 0.9996419059555516,\n",
       "  'eval_platform_accuracy': 0.9994331108044605,\n",
       "  'eval_product_precistion': 0.9651777403956997,\n",
       "  'eval_product_recall': 0.8430745133139405,\n",
       "  'eval_product_f1': 0.9000035831020905,\n",
       "  'eval_product_accuracy': 0.8413605340692948,\n",
       "  'eval_runtime': 457.4651,\n",
       "  'eval_samples_per_second': 293.061,\n",
       "  'eval_steps_per_second': 2.291,\n",
       "  'epoch': 1.5912586856203257,\n",
       "  'step': 60000},\n",
       " {'loss': 0.0002,\n",
       "  'grad_norm': 0.0010517823975533247,\n",
       "  'learning_rate': 0.0001469580438126558,\n",
       "  'epoch': 2.1216782474937674,\n",
       "  'step': 80000},\n",
       " {'eval_loss': 0.00014054009807296097,\n",
       "  'eval_platform_precistion': 0.999865673646662,\n",
       "  'eval_platform_recall': 0.9993958154626487,\n",
       "  'eval_platform_f1': 0.9996306893425897,\n",
       "  'eval_platform_accuracy': 0.9993958154626487,\n",
       "  'eval_product_precistion': 0.9726873612743178,\n",
       "  'eval_product_recall': 0.8890654135899158,\n",
       "  'eval_product_f1': 0.9289984178571707,\n",
       "  'eval_product_accuracy': 0.8863014209525231,\n",
       "  'eval_runtime': 457.5264,\n",
       "  'eval_samples_per_second': 293.021,\n",
       "  'eval_steps_per_second': 2.291,\n",
       "  'epoch': 2.1216782474937674,\n",
       "  'step': 80000},\n",
       " {'loss': 0.0001,\n",
       "  'grad_norm': 0.0007963682292029262,\n",
       "  'learning_rate': 0.00013369755476581977,\n",
       "  'epoch': 2.6520978093672096,\n",
       "  'step': 100000},\n",
       " {'eval_loss': 0.00011523207649588585,\n",
       "  'eval_platform_precistion': 0.9997389053419967,\n",
       "  'eval_platform_recall': 0.9996345056502443,\n",
       "  'eval_platform_f1': 0.9996867027704427,\n",
       "  'eval_platform_accuracy': 0.9996345056502443,\n",
       "  'eval_product_precistion': 0.9758052321185544,\n",
       "  'eval_product_recall': 0.9144998881181472,\n",
       "  'eval_product_f1': 0.9441584493891428,\n",
       "  'eval_product_accuracy': 0.9124678327676873,\n",
       "  'eval_runtime': 458.4727,\n",
       "  'eval_samples_per_second': 292.417,\n",
       "  'eval_steps_per_second': 2.286,\n",
       "  'epoch': 2.6520978093672096,\n",
       "  'step': 100000}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4cf5f1d1-0fa5-4bff-96f4-975600f9656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tnxs = [\n",
    "    {\n",
    "        'vendor_name': 'V391 Microsoft Office / Azure',\n",
    "        'memo': 'this is a test',\n",
    "        'memo_2': 'this is a name'\n",
    "    },\n",
    "    {\n",
    "        'vendor_name': 'Microsoft Azure',\n",
    "        'memo': 'monthly subscription azure - visual studio enterprise march 2022||abc123456',\n",
    "        'memo_2': 'Monthly Subscription Azure - Visual Studio Enterprise March 2022',\n",
    "    },\n",
    "    {\n",
    "        'vendor_name': 'Microsoft',\n",
    "        'memo': 'Office 365',\n",
    "        'memo_2': 'Office 365',\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f5e5a21-e01e-409d-a0df-ff32e3323426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = [gen_text(tnx) for tnx in test_tnxs]\n",
    "tokens = tokenizer(inputs, padding=True, truncation=True, max_length=max_length)\n",
    "input_ids = torch.tensor(tokens['input_ids']).to(device)\n",
    "attention_mask = torch.tensor(tokens['attention_mask']).to(device)\n",
    "pred = model(input_ids, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7cae74d0-625e-4e0a-a079-3639969471c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -8.9388,   5.7128, -12.4174,  ..., -17.6239, -19.2179, -15.9203])\n",
      "[('Microsoft', 'Microsoft Azure')]\n",
      "<Input>  {'vendor_name': 'V391 Microsoft Office / Azure', 'memo': 'this is a test', 'memo_2': 'this is a name'}\n",
      "<Prediction>\n",
      "  reseller:  ['']\n",
      "  product:  [('Microsoft', 'Microsoft Azure')]\n",
      "\n",
      "tensor([ -5.3705,   1.3113,  -9.0777,  ..., -10.7152, -10.8806,  -9.4025])\n",
      "[('Microsoft', 'Microsoft Azure'), ('Microsoft', 'Microsoft Visual Studio')]\n",
      "<Input>  {'vendor_name': 'Microsoft Azure', 'memo': 'monthly subscription azure - visual studio enterprise march 2022||abc123456', 'memo_2': 'Monthly Subscription Azure - Visual Studio Enterprise March 2022'}\n",
      "<Prediction>\n",
      "  reseller:  []\n",
      "  product:  [('Microsoft', 'Microsoft Azure'), ('Microsoft', 'Microsoft Visual Studio')]\n",
      "\n",
      "tensor([-10.2661, -13.5488, -14.4036,  ..., -18.9295, -19.2845, -17.4037])\n",
      "[('Microsoft', 'Microsoft 365')]\n",
      "<Input>  {'vendor_name': 'Microsoft', 'memo': 'Office 365', 'memo_2': 'Office 365'}\n",
      "<Prediction>\n",
      "  reseller:  ['']\n",
      "  product:  [('Microsoft', 'Microsoft 365')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tnx, x in zip(test_tnxs, pred.logits):\n",
    "    tmp = x.cpu().detach()\n",
    "    platform_logits = tmp[:platform_class_num]\n",
    "    product_logits = tmp[platform_class_num:]\n",
    "    platform_labels = []\n",
    "    product_labels = []\n",
    "    for i in np.where(platform_logits > 0)[0]:\n",
    "        platform_labels.append(platform_id_2_name[i])\n",
    "    for i in np.where(product_logits > 0)[0]:\n",
    "        product_labels.append(product_id_2_name[i + platform_class_num])\n",
    "    print(product_logits)\n",
    "    print(product_labels)\n",
    "    print('<Input> ', tnx)\n",
    "    print('<Prediction>')\n",
    "    print('  reseller: ', platform_labels)\n",
    "    print('  product: ', product_labels)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3a687dc-4d9c-4477-b8ba-7a841ec3d8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_platform_precistion</th>\n",
       "      <th>eval_platform_recall</th>\n",
       "      <th>eval_platform_f1</th>\n",
       "      <th>eval_platform_accuracy</th>\n",
       "      <th>eval_product_precistion</th>\n",
       "      <th>eval_product_recall</th>\n",
       "      <th>eval_product_f1</th>\n",
       "      <th>eval_product_accuracy</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.999232</td>\n",
       "      <td>0.999232</td>\n",
       "      <td>0.999232</td>\n",
       "      <td>0.999232</td>\n",
       "      <td>0.897417</td>\n",
       "      <td>0.478944</td>\n",
       "      <td>0.624564</td>\n",
       "      <td>0.478551</td>\n",
       "      <td>467.8766</td>\n",
       "      <td>286.539</td>\n",
       "      <td>2.240</td>\n",
       "      <td>0.530420</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.999724</td>\n",
       "      <td>0.999127</td>\n",
       "      <td>0.999425</td>\n",
       "      <td>0.999127</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.854246</td>\n",
       "      <td>0.770716</td>\n",
       "      <td>457.4811</td>\n",
       "      <td>293.050</td>\n",
       "      <td>2.291</td>\n",
       "      <td>1.060839</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.999806</td>\n",
       "      <td>0.999478</td>\n",
       "      <td>0.999642</td>\n",
       "      <td>0.999433</td>\n",
       "      <td>0.965178</td>\n",
       "      <td>0.843075</td>\n",
       "      <td>0.900004</td>\n",
       "      <td>0.841361</td>\n",
       "      <td>457.4651</td>\n",
       "      <td>293.061</td>\n",
       "      <td>2.291</td>\n",
       "      <td>1.591259</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.999866</td>\n",
       "      <td>0.999396</td>\n",
       "      <td>0.999631</td>\n",
       "      <td>0.999396</td>\n",
       "      <td>0.972687</td>\n",
       "      <td>0.889065</td>\n",
       "      <td>0.928998</td>\n",
       "      <td>0.886301</td>\n",
       "      <td>457.5264</td>\n",
       "      <td>293.021</td>\n",
       "      <td>2.291</td>\n",
       "      <td>2.121678</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.999739</td>\n",
       "      <td>0.999635</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>0.999635</td>\n",
       "      <td>0.975805</td>\n",
       "      <td>0.914500</td>\n",
       "      <td>0.944158</td>\n",
       "      <td>0.912468</td>\n",
       "      <td>458.4727</td>\n",
       "      <td>292.417</td>\n",
       "      <td>2.286</td>\n",
       "      <td>2.652098</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.999761</td>\n",
       "      <td>0.999552</td>\n",
       "      <td>0.999657</td>\n",
       "      <td>0.999552</td>\n",
       "      <td>0.976685</td>\n",
       "      <td>0.908317</td>\n",
       "      <td>0.941261</td>\n",
       "      <td>0.905740</td>\n",
       "      <td>457.6792</td>\n",
       "      <td>292.924</td>\n",
       "      <td>2.290</td>\n",
       "      <td>3.182517</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.999821</td>\n",
       "      <td>0.999657</td>\n",
       "      <td>0.999739</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.983598</td>\n",
       "      <td>0.937048</td>\n",
       "      <td>0.959759</td>\n",
       "      <td>0.935770</td>\n",
       "      <td>459.0332</td>\n",
       "      <td>292.059</td>\n",
       "      <td>2.283</td>\n",
       "      <td>3.712937</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.999784</td>\n",
       "      <td>0.999705</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.984533</td>\n",
       "      <td>0.942933</td>\n",
       "      <td>0.963284</td>\n",
       "      <td>0.942028</td>\n",
       "      <td>458.7562</td>\n",
       "      <td>292.236</td>\n",
       "      <td>2.284</td>\n",
       "      <td>4.243356</td>\n",
       "      <td>160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>0.999657</td>\n",
       "      <td>0.999724</td>\n",
       "      <td>0.999657</td>\n",
       "      <td>0.985980</td>\n",
       "      <td>0.949952</td>\n",
       "      <td>0.967630</td>\n",
       "      <td>0.949152</td>\n",
       "      <td>459.0382</td>\n",
       "      <td>292.056</td>\n",
       "      <td>2.283</td>\n",
       "      <td>4.773776</td>\n",
       "      <td>180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.999679</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>0.999735</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.986720</td>\n",
       "      <td>0.957127</td>\n",
       "      <td>0.971698</td>\n",
       "      <td>0.956499</td>\n",
       "      <td>457.5430</td>\n",
       "      <td>293.011</td>\n",
       "      <td>2.290</td>\n",
       "      <td>5.304196</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>0.999825</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>0.986973</td>\n",
       "      <td>0.961267</td>\n",
       "      <td>0.973950</td>\n",
       "      <td>0.960586</td>\n",
       "      <td>457.0329</td>\n",
       "      <td>293.338</td>\n",
       "      <td>2.293</td>\n",
       "      <td>5.834615</td>\n",
       "      <td>220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.999828</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>0.999810</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>0.989238</td>\n",
       "      <td>0.963258</td>\n",
       "      <td>0.976075</td>\n",
       "      <td>0.962839</td>\n",
       "      <td>458.7224</td>\n",
       "      <td>292.257</td>\n",
       "      <td>2.285</td>\n",
       "      <td>6.365035</td>\n",
       "      <td>240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.999784</td>\n",
       "      <td>0.999836</td>\n",
       "      <td>0.999810</td>\n",
       "      <td>0.999739</td>\n",
       "      <td>0.990104</td>\n",
       "      <td>0.964936</td>\n",
       "      <td>0.977358</td>\n",
       "      <td>0.964129</td>\n",
       "      <td>457.4428</td>\n",
       "      <td>293.075</td>\n",
       "      <td>2.291</td>\n",
       "      <td>6.895454</td>\n",
       "      <td>260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.999784</td>\n",
       "      <td>0.999814</td>\n",
       "      <td>0.999799</td>\n",
       "      <td>0.999746</td>\n",
       "      <td>0.990302</td>\n",
       "      <td>0.967278</td>\n",
       "      <td>0.978655</td>\n",
       "      <td>0.966643</td>\n",
       "      <td>457.8260</td>\n",
       "      <td>292.830</td>\n",
       "      <td>2.289</td>\n",
       "      <td>7.425874</td>\n",
       "      <td>280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999814</td>\n",
       "      <td>0.999836</td>\n",
       "      <td>0.999814</td>\n",
       "      <td>0.990916</td>\n",
       "      <td>0.967457</td>\n",
       "      <td>0.979046</td>\n",
       "      <td>0.967113</td>\n",
       "      <td>458.8571</td>\n",
       "      <td>292.172</td>\n",
       "      <td>2.284</td>\n",
       "      <td>7.956293</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    eval_loss  eval_platform_precistion  eval_platform_recall  \\\n",
       "0    0.000616                  0.999232              0.999232   \n",
       "1    0.000281                  0.999724              0.999127   \n",
       "2    0.000191                  0.999806              0.999478   \n",
       "3    0.000141                  0.999866              0.999396   \n",
       "4    0.000115                  0.999739              0.999635   \n",
       "5    0.000110                  0.999761              0.999552   \n",
       "6    0.000083                  0.999821              0.999657   \n",
       "7    0.000076                  0.999627              0.999784   \n",
       "8    0.000067                  0.999791              0.999657   \n",
       "9    0.000060                  0.999679              0.999791   \n",
       "10   0.000056                  0.999858              0.999791   \n",
       "11   0.000051                  0.999828              0.999791   \n",
       "12   0.000048                  0.999784              0.999836   \n",
       "13   0.000045                  0.999784              0.999814   \n",
       "14   0.000044                  0.999858              0.999814   \n",
       "\n",
       "    eval_platform_f1  eval_platform_accuracy  eval_product_precistion  \\\n",
       "0           0.999232                0.999232                 0.897417   \n",
       "1           0.999425                0.999127                 0.955056   \n",
       "2           0.999642                0.999433                 0.965178   \n",
       "3           0.999631                0.999396                 0.972687   \n",
       "4           0.999687                0.999635                 0.975805   \n",
       "5           0.999657                0.999552                 0.976685   \n",
       "6           0.999739                0.999627                 0.983598   \n",
       "7           0.999705                0.999597                 0.984533   \n",
       "8           0.999724                0.999657                 0.985980   \n",
       "9           0.999735                0.999627                 0.986720   \n",
       "10          0.999825                0.999791                 0.986973   \n",
       "11          0.999810                0.999791                 0.989238   \n",
       "12          0.999810                0.999739                 0.990104   \n",
       "13          0.999799                0.999746                 0.990302   \n",
       "14          0.999836                0.999814                 0.990916   \n",
       "\n",
       "    eval_product_recall  eval_product_f1  eval_product_accuracy  eval_runtime  \\\n",
       "0              0.478944         0.624564               0.478551      467.8766   \n",
       "1              0.772686         0.854246               0.770716      457.4811   \n",
       "2              0.843075         0.900004               0.841361      457.4651   \n",
       "3              0.889065         0.928998               0.886301      457.5264   \n",
       "4              0.914500         0.944158               0.912468      458.4727   \n",
       "5              0.908317         0.941261               0.905740      457.6792   \n",
       "6              0.937048         0.959759               0.935770      459.0332   \n",
       "7              0.942933         0.963284               0.942028      458.7562   \n",
       "8              0.949952         0.967630               0.949152      459.0382   \n",
       "9              0.957127         0.971698               0.956499      457.5430   \n",
       "10             0.961267         0.973950               0.960586      457.0329   \n",
       "11             0.963258         0.976075               0.962839      458.7224   \n",
       "12             0.964936         0.977358               0.964129      457.4428   \n",
       "13             0.967278         0.978655               0.966643      457.8260   \n",
       "14             0.967457         0.979046               0.967113      458.8571   \n",
       "\n",
       "    eval_samples_per_second  eval_steps_per_second     epoch    step  \n",
       "0                   286.539                  2.240  0.530420   20000  \n",
       "1                   293.050                  2.291  1.060839   40000  \n",
       "2                   293.061                  2.291  1.591259   60000  \n",
       "3                   293.021                  2.291  2.121678   80000  \n",
       "4                   292.417                  2.286  2.652098  100000  \n",
       "5                   292.924                  2.290  3.182517  120000  \n",
       "6                   292.059                  2.283  3.712937  140000  \n",
       "7                   292.236                  2.284  4.243356  160000  \n",
       "8                   292.056                  2.283  4.773776  180000  \n",
       "9                   293.011                  2.290  5.304196  200000  \n",
       "10                  293.338                  2.293  5.834615  220000  \n",
       "11                  292.257                  2.285  6.365035  240000  \n",
       "12                  293.075                  2.291  6.895454  260000  \n",
       "13                  292.830                  2.289  7.425874  280000  \n",
       "14                  292.172                  2.284  7.956293  300000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_log_df = pd.DataFrame([x for x in trainer.state.log_history if 'eval_runtime' in x])\n",
    "train_log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9b1e962e-b20a-4bf5-83d2-ceb514d88373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9e45dc-93db-454b-a921-aa6dae33eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tra"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
