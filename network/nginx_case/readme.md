# Nginx 卡顿复现方案
## 术语
- 快连接：通常是传输时间短、传输量小的连接，耗时通常是ms级别，每次请求都会三次握手四次挥手
- 慢连接：通常是传输时间长、传输量大的连接，可以维持传输状态一段时间（如30s, 1min）
## 现象
摘抄自plantegg的blog
>从2018年开始，我们有个业务陆续接到反馈 Nginx 线上集群经常出现不响应或者偶发性的“超慢”请求，请求不响应，影响用户业务，这种卡顿每天都有少量出现。  
>而只有多个集群中的一个出现，其他压力更大的集群皆未出现.  
>业务结构比较简单：LVS->Nginx->后端，如图  

![screenshot.png]()

>出问题前不久升级 nginx 配置，打开了 reuse_port 功能  
>在压力大的后端（upstream）服务环境不容易出现，后端压力轻对应的Nginx 卡顿概率更高  
>关闭 reuse_port 后 问题少了很多  
>失败的请求响应时间都是 0ms（Nginx日志不靠谱了）  
>从 nginx 日志上看，所有失败的健康检查请求都是0ms 的499 错误码（健康检查设置超时是2秒），但实际出问题的时候有5s-2分钟没有任何日志输出（Nginx卡了这么久）-- 要么是Nginx卡住没去accept，要么是accept了没响应
>所有超时来自同一个worker(一个Nginx服务一般按照机器核数开启多个worker)

## 原因分析
nginx是多进程模型，为了尽可能利用cpu。每个worker进程都有一个独立的epoll，每个epoll都会监听相同的端口，当有新连接到来时，会通过负载均衡算法分配给某个worker进程，然后由该worker进程处理该连接。

如果nginx的worker进程数量足够少，且新连接数目足够多，就会出现多个连接绑定同一个worker的情况。假设该worker上某个连接是大文件慢传输，且网络传输十分流畅（recv buffer始终有数据），那么就有可能出现该worker专注于传输这一个一个连接的数据的情况（epoll一直读取这个连接的数据，无法切换到其他连接）。这时候对于另一个连接来说，就会观测到卡顿情况。

## 尝试复现
### 思路
1. 整体的架构是N个client->1个Nginx->N个server，慢连接和快连接分别在不同的client进行，便于抓包、观测
2. 进程数量要足够少  
`worker_processes 2;`
3. 连接数目要足够多，且有快连接有慢连接，慢连接数目>=2，使得连接在分配时，有一定概率分配到同一个worker上，考虑到aws是通过间歇掉包来限速的，该数字并非越大越好，否则引发限速后反而会造成网络连接不畅，使得快连接卡顿不容易观测。
4. reuseport: 这是nginx解决惊群问题的优秀方案，内核通过哈希算法，将新链接相对均衡地分配到各个开启了reuseport属性的进程，避免上下文切换的出现，但也是由于这个分配机制，worker更有可能专注于读取某个慢连接数据而忽视快连接建立的请求，从而造成卡顿。这个配置要开启，开盾才更容易观测到。  
`listen 8000 reuseport;`
### 过程
#### 方案1
环境：全部使用AWS t2.micro  
架构：2个client，1个nginx，2个server  

这个过程中主要是摸索nginx配置，首先把nginx配置成和server, client都能连接上的状态，编写test script，加上各种耗时监测，调试nginx的log输出格式，最后得到一个比较完善的测试环境。

首先测试了开2个慢连接进程，1个快连接进程，已经能观测到快连接耗时不稳定的情况，短的在几十ms，长的在几秒，但是access.log没有499。
499是client close request error，也就意味着出这个error原因是客户端主动关连接，那么如何让客户端主动关连接呢？可以在curl里设置 --max-time，比如设置成1s，这样客户端就会在没有收到SYN,ACK的情况下主动关掉连接，这样就能在nginx观测到499了。

```

```
#### 方案2
环境：全部使用AWS t2.micro  
架构：2个client，1个nginx，1个server  
在过程中发现t2.micro非常容易被限速，特别是在开3-4个慢连接下载进程的过程中，这种情况下一般观测不到卡顿，只能观测到在1s内文件下载不完
```
172.31.91.109 [31/May/2023:08:27:44 +0000] "GET /server.pcap HTTP/1.1" status=200 body_bytes_sent=515891 rt=0.699 uct="0.279" uht="0.379" urt="0.699"
172.31.91.109 [31/May/2023:08:27:45 +0000] "GET /server.pcap HTTP/1.1" status=200 body_bytes_sent=534951 rt=0.857 uct="0.206" uht="0.347" urt="0.857"
172.31.91.109 [31/May/2023:08:27:46 +0000] "GET /server.pcap HTTP/1.1" status=200 body_bytes_sent=2126089 rt=0.919 uct="0.204" uht="0.320" urt="0.668"
172.31.91.109 [31/May/2023:08:27:47 +0000] "GET /server.pcap HTTP/1.1" status=200 body_bytes_sent=1394055 rt=0.667 uct="0.014" uht="0.028" urt="0.537"
```

#### 方案3
环境：1台AWS t2.micro（一个client），3台AWS t3.micro（1个client，1个nginx，1个server）  
架构：2个client，1个nginx，1个server  